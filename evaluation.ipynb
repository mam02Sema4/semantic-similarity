{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparativa de Word2Vec, GloVe y FastText para obtener la similaridad semántica entre pares de textos\n",
    "## Pablo Valdunciel Sánchez \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el modelo *KeyedVectors* de la librería [*gesim*](https://radimrehurek.com/gensim/index.html) para cargar los vectores pre-entrenados de los diferentes modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los vectores pre-entrenados con modelos Word2Vec, GloVe y FastText. Los vectores pre-entrenados de cada modelo utilizados son:\n",
    "\n",
    "- **Word2Vec**:  [GoogleNews-vectors-negative300.bin.gz](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit)  \n",
    "- **GloVe**: [Common  Crawl  (840B  tokens,2.2M vocab, cased, 300d vectors)](http://nlp.stanford.edu/data/glove.840B.300d.zip)\n",
    "- **FastText**: [rawl-300d-2M.vec.zip:  2  million  word  vectors  trained  on  Common  Crawl  (600Btokens)](https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip)\n",
    "\n",
    "En el caso de los vectores de GloVe, se ha utilizado la función [*gensim.scripts.glove2word2vec.glove2word2vec*](https://radimrehurek.com/gensim/scripts/glove2word2vec.html) para convertir el archivo al formato Word2Vec.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WORD2VEC = './data/embedding/word2vec/GoogleNews-vectors-negative300.bin'\n",
    "PATH_GLOVE = './data/embedding/glove/glove.840B.300d.w2v.txt'\n",
    "PATH_FASTTEXT = './data/embedding/fasttext/crawl-300d-2M.vec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los vectores puede llevar varios minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(PATH_WORD2VEC, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(PATH_GLOVE, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = KeyedVectors.load_word2vec_format(PATH_FASTTEXT, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo uso de las funciones del módulo *load.py* cargamos los conjuntos de test de las tareas STS12, STS13, STS14, STS15 y STS16. Estas funciones llevan a cabo un preprocesamiento de las oraciones según los parámetros que se indiquen. Entre las posibilidades de preprocesamiento se encuentran:\n",
    "\n",
    "- **lowercase**: hacer que todas las palabras estén en minúscula.\n",
    "- **stop_words**: eliminar las palabras que no aportan casi significado semántico como determinantes, preprosiciones, etc.\n",
    "- **punctuation**: elminar los símbolos de puntuación.\n",
    "- **only_ascci**: eliminar las palabras que no estén formadas por caracteres ASCII.\n",
    "- **lemmatization**: sustituir las palabras por su lexema.\n",
    "\n",
    "El preprocesamiento del texto está implementado en la función *preprocess* en el módulo *utils.py*. La función *preprocess* hace uso de la librería [spaCy](https://spacy.io/) para llevar a cabo el preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import load_sts_12, load_sts_13, load_sts_14, load_sts_15, load_sts_16\n",
    "from load import load_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no se aplica ningún tipo de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = './data/datasets/STS'\n",
    "PATH_FREQUENCIES = './data/frequencies.tsv'\n",
    "PREPROCESSING =  {'lowercase':  False, \n",
    "                  'stop_words': False, \n",
    "                  'punctuation': False, \n",
    "                  'only_ascii': False, \n",
    "                  'lemmatization': False\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos también las frecuencias de las palabras en el corpus par poder aplicar el SIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = load_frequencies(PATH_FREQUENCIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** TASK: STS12 *****\n",
      "\n",
      "Preprocessing -MSRpar-\n",
      "-MSRpar- preprocessed correctly\n",
      "Preprocessing -MSRvid-\n",
      "-MSRvid- preprocessed correctly\n",
      "Preprocessing -SMTeuroparl-\n",
      "-SMTeuroparl- preprocessed correctly\n",
      "Preprocessing -surprise.OnWN-\n",
      "-surprise.OnWN- preprocessed correctly\n",
      "Preprocessing -surprise.SMTnews-\n",
      "-surprise.SMTnews- preprocessed correctly\n",
      "\n",
      "***** TASK: STS13 (-SMT) ***\n",
      "\n",
      "\n",
      "Preprocessing -FNWN-\n",
      "-FNWN- preprocessed correctly\n",
      "Preprocessing -headlines-\n",
      "-headlines- preprocessed correctly\n",
      "Preprocessing -OnWN-\n",
      "-OnWN- preprocessed correctly\n",
      "\n",
      "***** TASK: STS14 *****\n",
      "\n",
      "Preprocessing -deft-forum-\n",
      "-deft-forum- preprocessed correctly\n",
      "Preprocessing -deft-news-\n",
      "-deft-news- preprocessed correctly\n",
      "Preprocessing -headlines-\n",
      "-headlines- preprocessed correctly\n",
      "Preprocessing -images-\n",
      "-images- preprocessed correctly\n",
      "Preprocessing -OnWN-\n",
      "-OnWN- preprocessed correctly\n",
      "Preprocessing -tweet-news-\n",
      "-tweet-news- preprocessed correctly\n",
      "\n",
      "***** TASK: STS15 *****\n",
      "\n",
      "Preprocessing -answers-forums-\n",
      "-answers-forums- preprocessed correctly\n",
      "Preprocessing -answers-students-\n",
      "-answers-students- preprocessed correctly\n",
      "Preprocessing -belief-\n",
      "-belief- preprocessed correctly\n",
      "Preprocessing -headlines-\n",
      "-headlines- preprocessed correctly\n",
      "Preprocessing -images-\n",
      "-images- preprocessed correctly\n",
      "\n",
      "***** TASK: STS16 *****\n",
      "\n",
      "Preprocessing -answer-answer-\n",
      "-answer-answer- preprocessed correctly\n",
      "Preprocessing -headlines-\n",
      "-headlines- preprocessed correctly\n",
      "Preprocessing -plagiarism-\n",
      "-plagiarism- preprocessed correctly\n",
      "Preprocessing -postediting-\n",
      "-postediting- preprocessed correctly\n",
      "Preprocessing -question-question-\n",
      "-question-question- preprocessed correctly\n"
     ]
    }
   ],
   "source": [
    "sts12 = load_sts_12(PATH_DATASETS, PREPROCESSING)\n",
    "sts13 = load_sts_13(PATH_DATASETS, PREPROCESSING)\n",
    "sts14 = load_sts_14(PATH_DATASETS, PREPROCESSING)\n",
    "sts15 = load_sts_15(PATH_DATASETS, PREPROCESSING)\n",
    "sts16 = load_sts_16(PATH_DATASETS, PREPROCESSING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Métodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos para calcular la similaridad semántica entre dos oraciones son:\n",
    "\n",
    "- **avg_cosine**: el vector de una oración se obtiene haciendo la media (*average*) de los vectores de las palabras de esa oración. La similaridad entre dos vectores se calcula utilizando la similitud coseno.\n",
    "- **avg_cosine**: el vector de una oración se obtiene haciendo la media (*average*) de los vectores de las palabras de esa oración. La similaridad entre dos vectores se calcula utilizando la similitud coseno.\n",
    "- **wmd**: la similariad entre dos oraciones se calcula como el contrario de ladistancia *Word Mover's Distance* entre las mismas. El modelo *KeyedVectors* de *gensim* incorpora el cálculo de esta distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from methods import avg_cosine, wmd, sif_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = [\n",
    "    (\"Word2Vec + AVG\", partial(avg_cosine, model=word2vec)),\n",
    "    (\"Word2Vec + SIF\", partial(sif_cosine, model=word2vec, frequencies=freqs, a=0.001)),\n",
    "    (\"Word2Vec + WMD\", partial(wmd, model=word2vec)),   \n",
    "    (\"GloVe + AVG\", partial(avg_cosine, model=glove)),\n",
    "    (\"GloVe + SIF\", partial(sif_cosine, model=glove, frequencies=freqs, a=0.001)),\n",
    "    (\"GloVe + WMD\", partial(wmd, model=glove)),    \n",
    "    (\"FastText + AVG\", partial(avg_cosine, model=fasttext)),\n",
    "    (\"FastText + SIF\", partial(sif_cosine, model=fasttext, frequencies=freqs, a=0.001)),\n",
    "    (\"FastText + WMD\", partial(wmd, model=fasttext))    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts12_pearson, sts12_spearman = evaluate(sts12, METHODS)\n",
    "sts13_pearson, sts13_spearman = evaluate(sts13, METHODS)\n",
    "sts14_pearson, sts14_spearman = evaluate(sts14, METHODS)\n",
    "sts15_pearson, sts15_spearman = evaluate(sts15, METHODS)\n",
    "sts16_pearson, sts16_spearman = evaluate(sts16, METHODS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++ Task STS12 ++++\n",
      "{'FastText + AVG': 0.6005548609319203,\n",
      " 'FastText + SIF': 0.6212579120092905,\n",
      " 'FastText + WMD': 0.5535246774015393,\n",
      " 'GloVe + AVG': 0.550325345521787,\n",
      " 'GloVe + SIF': 0.5887005481387919,\n",
      " 'GloVe + WMD': 0.5511226507959358,\n",
      " 'Word2Vec + AVG': 0.5576731761229754,\n",
      " 'Word2Vec + SIF': 0.5675778156670679,\n",
      " 'Word2Vec + WMD': 0.4735133931943548}\n",
      "\n",
      "++++ Task STS13 ++++\n",
      "\n",
      "{'FastText + AVG': 0.6395854651348138,\n",
      " 'FastText + SIF': 0.743114999290766,\n",
      " 'FastText + WMD': 0.5043251957475268,\n",
      " 'GloVe + AVG': 0.5430947980396821,\n",
      " 'GloVe + SIF': 0.7003751891752676,\n",
      " 'GloVe + WMD': 0.48648450234493545,\n",
      " 'Word2Vec + AVG': 0.6402354732298344,\n",
      " 'Word2Vec + SIF': 0.7226844714342786,\n",
      " 'Word2Vec + WMD': 0.5212277588700386}\n",
      "\n",
      "++++ Task STS14 ++++\n",
      "\n",
      "{'FastText + AVG': 0.666441560463602,\n",
      " 'FastText + SIF': 0.7356129023314942,\n",
      " 'FastText + WMD': 0.5920864958135631,\n",
      " 'GloVe + AVG': 0.5624817686550272,\n",
      " 'GloVe + SIF': 0.7068915343232387,\n",
      " 'GloVe + WMD': 0.5803043426949426,\n",
      " 'Word2Vec + AVG': 0.6867847666634713,\n",
      " 'Word2Vec + SIF': 0.7279177178075755,\n",
      " 'Word2Vec + WMD': 0.6121970541331052}\n",
      "\n",
      "++++ Task STS15 ++++\n",
      "\n",
      "{'FastText + AVG': 0.6998534252993311,\n",
      " 'FastText + SIF': 0.761278289996281,\n",
      " 'FastText + WMD': 0.6887872169458182,\n",
      " 'GloVe + AVG': 0.6006241865061205,\n",
      " 'GloVe + SIF': 0.7319276750876433,\n",
      " 'GloVe + WMD': 0.6796406524692465,\n",
      " 'Word2Vec + AVG': 0.7048782478026994,\n",
      " 'Word2Vec + SIF': 0.7489534387403396,\n",
      " 'Word2Vec + WMD': 0.6838824012601197}\n",
      "\n",
      "++++ Task STS16 ++++\n",
      "\n",
      "{'FastText + AVG': 0.6326237499753964,\n",
      " 'FastText + SIF': 0.7315395720676849,\n",
      " 'FastText + WMD': 0.6312212885648231,\n",
      " 'GloVe + AVG': 0.5025433957938354,\n",
      " 'GloVe + SIF': 0.6846682589318798,\n",
      " 'GloVe + WMD': 0.6132747807563322,\n",
      " 'Word2Vec + AVG': 0.6390942371456013,\n",
      " 'Word2Vec + SIF': 0.7190592212454177,\n",
      " 'Word2Vec + WMD': 0.6408015822267789}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n++++ Task STS12 ++++\")\n",
    "pprint.pprint(sts12_pearson, width=1)\n",
    "print(\"\\n++++ Task STS13 ++++\\n\")\n",
    "pprint.pprint(sts13_pearson, width=1)\n",
    "print(\"\\n++++ Task STS14 ++++\\n\")\n",
    "pprint.pprint(sts14_pearson, width=1)\n",
    "print(\"\\n++++ Task STS15 ++++\\n\")\n",
    "pprint.pprint(sts15_pearson, width=1)\n",
    "print(\"\\n++++ Task STS16 ++++\\n\")\n",
    "pprint.pprint(sts16_pearson, width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
